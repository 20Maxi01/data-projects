{
 "cells": [
  {
   "metadata": {
    "id": "c266e7b01c934543"
   },
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning deepset/gbert-base for German Hate Speech Classification\n",
    "This notebook fine-tunes `deepset/gbert-base` on a German hate speech dataset using PyTorch, BERT and adding an additional fully connected layer.\n",
    "\n",
    "For the hyperparameter tuning optuna and the Tree-structured Parzen estimator (TPE), a Bayesian optimization method is used.\n",
    "\n",
    "The script automatically logs the model metrics to the wandb project as well as to \"logged_model_metrics.xlsx\"\n",
    "\n"
   ],
   "id": "c266e7b01c934543"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install optuna"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elTvBEPh-GEN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037945743,
     "user_tz": -60,
     "elapsed": 3870,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "f13ecbd9-776e-4eb7-f510-2ae1d8f0bc55"
   },
   "id": "elTvBEPh-GEN",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m364.4/364.4 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m233.5/233.5 kB\u001B[0m \u001B[31m23.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.6/78.6 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Import Libraries\n",
    "import wandb\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score\n",
    "    , precision_recall_fscore_support\n",
    "    , matthews_corrcoef\n",
    "    , classification_report\n",
    "    , f1_score\n",
    "    , log_loss\n",
    "    , precision_score\n",
    "    , recall_score\n",
    "    , fbeta_score\n",
    "    , confusion_matrix\n",
    "    , ConfusionMatrixDisplay\n",
    ")\n",
    "from transformers import AutoTokenizer, BertModel, Trainer, TrainingArguments\n",
    "import logging\n",
    "import os\n",
    "from google.colab import runtime, userdata, drive\n",
    "import datetime\n",
    "import threading\n",
    "import time"
   ],
   "metadata": {
    "id": "8Oyu0U0D-Jct"
   },
   "id": "8Oyu0U0D-Jct",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up logging and connections"
   ],
   "metadata": {
    "id": "FSv5W-8gG53A"
   },
   "id": "FSv5W-8gG53A"
  },
  {
   "cell_type": "code",
   "source": [
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Log INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    force=True\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "id": "EMOvE2y8-M-C"
   },
   "id": "EMOvE2y8-M-C",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# connect to wandb\n",
    "wandbkey = userdata.get('WandbKey')\n",
    "\n",
    "wandb.login(key=wandbkey)"
   ],
   "metadata": {
    "id": "eNnUSAiW-l2E",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037965512,
     "user_tz": -60,
     "elapsed": 2566,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "6bbbfc25-5068-445e-95bd-c650d46e8a5d"
   },
   "id": "eNnUSAiW-l2E",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmaxnienh\u001B[0m (\u001B[33mmaxnienh-xx\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set Device to GPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n"
   ],
   "metadata": {
    "id": "mNCe_zjs-Pe_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037965513,
     "user_tz": -60,
     "elapsed": 7,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "5169575a-ef65-44b2-e059-5d87372f6e6c"
   },
   "id": "mNCe_zjs-Pe_",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-01-05 00:46:05,217 - INFO - Using device: cuda\n",
      "2025-01-05 00:46:05,240 - INFO - GPU Name: NVIDIA L4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# mount google drive for folder access\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "z1bi-ZSU070r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037983499,
     "user_tz": -60,
     "elapsed": 17991,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "0cdf8c3c-8b6f-4722-94e0-592240e406c7"
   },
   "id": "z1bi-ZSU070r",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define custom BERT model class"
   ],
   "metadata": {
    "id": "H7xOkBorGuCQ"
   },
   "id": "H7xOkBorGuCQ"
  },
  {
   "cell_type": "code",
   "source": [
    "class BERT_WithExtraLayer(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_labels=2, hidden_dim=256, dropout_rate=0.1, class_weights=None):\n",
    "        \"\"\"\n",
    "        Initializes a BERT-based model with an additional fully connected layer.\n",
    "\n",
    "        :param bert_model_name: Name of the pre-trained BERT model to be used.\n",
    "        :param num_labels: Number of output classes for classification.\n",
    "        :param hidden_dim: Size of the hidden layer in the additional fully connected network.\n",
    "        :param dropout_rate: Dropout rate for regularization.\n",
    "        :param class_weights: Optional tensor containing class weights for handling class imbalance.\n",
    "        \"\"\"\n",
    "         \n",
    "        super(BERT_WithExtraLayer, self).__init__()\n",
    "\n",
    "        # Load pre-trained BERT model\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # Additional fully connected layer\n",
    "        self.extra_fc = nn.Linear(self.hidden_size, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        :param input_ids: Tensor of tokenized input IDs.\n",
    "        :param attention_mask: Tensor indicating which tokens should be attended to.\n",
    "        :param labels: Optional tensor of target labels for loss calculation.\n",
    "        :return: During training: (loss, logits), During inference: logits\n",
    "        \"\"\"\n",
    "        \n",
    "        # Forward pass through BERT\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Forward pass through extra layer\n",
    "        x = self.extra_fc(pooled_output)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Classification layer\n",
    "        logits = self.classifier(x)  # Shape: (batch_size, num_labels)\n",
    "\n",
    "        # Compute loss if labels are provided\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=class_weights) # for balancing the classes\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "            return loss, logits\n",
    "\n",
    "        return logits"
   ],
   "metadata": {
    "id": "uho-iaYN554o"
   },
   "id": "uho-iaYN554o",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load, split and tokenize data"
   ],
   "metadata": {
    "id": "yXvMWQa9G-Yc"
   },
   "id": "yXvMWQa9G-Yc"
  },
  {
   "cell_type": "code",
   "source": [
    "#import pandas as pd\n",
    "dataset_filename = \"Dataset_anonymized_annotated_comments_same_annotation_final.csv\"\n",
    "csv_path = os.path.join('/content/drive/MyDrive/model/data', dataset_filename)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(csv_path, delimiter=';', on_bad_lines='skip')\n",
    "data = data[['comment', 'annotation']]\n",
    "logger.info(f\"Dataset loaded with shape: {data.shape}\")\n",
    "\n",
    "# Compute Class Weights using the normalized formula\n",
    "class_counts = data['annotation'].value_counts().sort_index()\n",
    "total_samples = class_counts.sum()\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "# Improved inverse class weights\n",
    "class_weights = total_samples / (num_classes * class_counts)\n",
    "class_weights = torch.tensor(class_weights.values, dtype=torch.float32).to(device)\n",
    "\n",
    "logger.info(f\"Computed class weights: {class_weights}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbMB67QN-Tj2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037985287,
     "user_tz": -60,
     "elapsed": 1791,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "dcb906bc-4ad4-4100-aed7-5608e4276916"
   },
   "id": "YbMB67QN-Tj2",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-01-05 00:46:24,444 - INFO - Dataset loaded with shape: (23580, 2)\n",
      "2025-01-05 00:46:24,999 - INFO - Computed class weights: tensor([0.7221, 1.6258], device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Variable to switch betwenn full and small dataset (for tests)\n",
    "use_full_dataset = 1\n",
    "\n",
    "# Split into training (70%), validation (15%), and test (15%) datasets\n",
    "if use_full_dataset == 1:\n",
    "\n",
    "  train_data, temp_data = train_test_split(data, test_size=0.3, stratify=data['annotation'], random_state=42)\n",
    "  val_data, test_data = train_test_split(temp_data, test_size=0.5, stratify=temp_data['annotation'], random_state=42)\n",
    "\n",
    "  logger.info(f\"Train size: {len(train_data)} rows | Test size: {len(test_data)} rows | Validation size: {len(val_data)} rows\")\n",
    "\n",
    "else:\n",
    "  #Separate Dataset into two groups\n",
    "  hate_data = data[data['annotation'] == 1]\n",
    "  no_hate_data = data[data['annotation'] == 0]\n",
    "\n",
    "  #Take n random comments out of both groups to create a balanced dataset\n",
    "  subset_size_per_class = 500\n",
    "  positive_subset = hate_data.sample(n=subset_size_per_class, random_state=42)\n",
    "  negative_subset = no_hate_data.sample(n=subset_size_per_class, random_state=42)\n",
    "\n",
    "  # Combine both groups into one dataset\n",
    "  balanced_subset = pd.concat([positive_subset, negative_subset])\n",
    "\n",
    "  # Shuffle and reset index\n",
    "  balanced_subset = balanced_subset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "  # Verify balance\n",
    "  logger.info(f\"Balanced subset size: {len(balanced_subset)} rows\")\n",
    "  logger.info(f\"Annotation distribution: {balanced_subset['annotation'].value_counts()}\")\n",
    "\n",
    "  train_size = int(0.7 * len(balanced_subset))\n",
    "  val_size = int(0.15 * len(balanced_subset))\n",
    "\n",
    "  train_data = balanced_subset[:train_size]\n",
    "  val_data = balanced_subset[train_size:train_size + val_size]\n",
    "  test_data = balanced_subset[train_size + val_size:]\n",
    "\n",
    "  # Log sizes of each split\n",
    "  logger.info(f\"Small Train size: {len(train_data)} rows | Small Test size: {len(test_data)} rows | Small Validation size: {len(val_data)} rows\")\n"
   ],
   "metadata": {
    "id": "5Fyezy2X-Vyo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037985287,
     "user_tz": -60,
     "elapsed": 5,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "65ef496a-ad9a-4b7b-a5f3-ebe34f2b8cde"
   },
   "id": "5Fyezy2X-Vyo",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-01-05 00:46:25,023 - INFO - Train size: 16506 rows | Test size: 3537 rows | Validation size: 3537 rows\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "id": "cm-xN4dHRA0M"
   },
   "id": "cm-xN4dHRA0M"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/gbert-base')\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_texts(texts, tokenizer, max_length=256): # reduced for testing\n",
    "    \"\"\"\n",
    "    Tokenizes a list of input texts.\n",
    "\n",
    "    :param texts: List of input text strings.\n",
    "    :param tokenizer: Tokenizer to be used (e.g., BERT tokenizer).\n",
    "    :param max_length: Maximum sequence length for tokenization.\n",
    "    :return: Dictionary of tokenized outputs, including input IDs and attention masks.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Tokenize train and test datasets\n",
    "train_encodings = tokenize_texts(train_data['comment'], tokenizer)\n",
    "val_encodings = tokenize_texts(val_data['comment'], tokenizer)\n",
    "test_encodings = tokenize_texts(test_data['comment'], tokenizer)\n",
    "\n",
    "# Define Dataset class\n",
    "class HateSpeechDataset(Dataset):   \n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Custom dataset class for handling tokenized text and labels.\n",
    "    \n",
    "        :param encodings: Tokenized text data.\n",
    "        :param labels: Corresponding labels for classification.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample from the dataset.\n",
    "        \n",
    "        :param idx: Index of the sample to retrieve.\n",
    "        :return: Dictionary containing tokenized inputs and label.\n",
    "        \"\"\"\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "\n",
    "        :return: Integer count of samples.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_data['annotation'].values)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_data['annotation'].values)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_data['annotation'].values)\n",
    "logger.info(f\"Training samples: {len(train_dataset)} | Test samples: {len(test_dataset)} | Validation samples: {len(val_dataset)}\")"
   ],
   "metadata": {
    "id": "zwFC0nbE-Y4Y",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "referenced_widgets": [
      "b2c9e8b033f1451e89d2efb8f72caec5",
      "774c1612763c4b71a831a9fff5af4b9b",
      "af99f15763a14caaa099176dd4834950",
      "f84a8cc972e747269372bff1058391a9",
      "1bf21ae404ce4eb5861e0d90c1a5c90b",
      "cb21b8d54b6748ddaea92b59f65ded40",
      "da386aeb94a74293bb41f3055d784924",
      "82620d7f165c4dea9bfda4c1552a8ef3",
      "23e8053878a54447bebb3ef351a90eff",
      "9b7b369c167141c0aef96d926c885ad8",
      "36b9a5f2e38c4413ae9763961106e2a4",
      "ac0be628989645e986f4944a8b0acb52",
      "8d136d7a74154b94833d1ac1edf4d3b4",
      "14071f4d05a64ac1be14620a56e17f04",
      "0ef914e20a7841cbbe852b2fd492be5c",
      "e7aebb90a6074a60a472f2aaba925d78",
      "f09de98447f34fb690b06b8138c2b499",
      "b96367c3c55b475fbe0c01bb507d8f63",
      "b806cf0d9b604b0197aa66519e6e2eff",
      "ed839d82b0d54aba84b469fb625f2504",
      "3a0a452bb92e4bdb8892dfdae6dc0dd0",
      "81a1c27ab3cf433396ba6e3578ab6e2f",
      "01b6eff419654533bb487875ba6f95a4",
      "2e5e450f26bf4eccba5e4d0ca76504bc",
      "03fe074b30e34202b65379a70eeef9bb",
      "ced62a16e9b44ee59f285205a06c6d04",
      "be6c5d1ba184453fb14dcf2edfbd6d97",
      "b111594fae8b400585cd661c17189f56",
      "b2690f0494fc4525a4bfc1505cdec409",
      "9fc65ce5a0c34ab1a6aafcedace9237e",
      "f590cd58c9cc428c967d954153498e2b",
      "94b6d3326d044c3fa50c2104f7dac56e",
      "67563fe012ab4ac382a4d7159ddec5f0"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1736037992641,
     "user_tz": -60,
     "elapsed": 7358,
     "user": {
      "displayName": "Max N.",
      "userId": "17347375569055604559"
     }
    },
    "outputId": "fef01f66-b973-4a04-9c5b-8ac544023719"
   },
   "id": "zwFC0nbE-Y4Y",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/83.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2c9e8b033f1451e89d2efb8f72caec5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/362 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac0be628989645e986f4944a8b0acb52"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/240k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01b6eff419654533bb487875ba6f95a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-01-05 00:46:32,300 - INFO - Training samples: 16506 | Test samples: 3537 | Validation samples: 3537\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the function for calculating metrics and training"
   ],
   "metadata": {
    "id": "tdqsLmqOHEfJ"
   },
   "id": "tdqsLmqOHEfJ"
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred, trial=None, trainer=None):\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics for classification.\n",
    "\n",
    "    :param eval_pred: Tuple containing predictions and labels.\n",
    "    :param trial: Optional Optuna trial object for hyperparameter tuning.\n",
    "    :param trainer: Optional Trainer object for tracking progress.\n",
    "    :return: Dictionary containing accuracy, precision, recall, F1-score, and other metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # metrics computation for model evaluation, WandB tracking, and Optuna pruning.\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=1)  # Predictions\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    f2 = fbeta_score(labels, preds, beta=2, average='binary')\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    mcc_normalized = (mcc + 1) / 2\n",
    "    S = (f2 + mcc_normalized) / 2\n",
    "\n",
    "    # Prepare metrics dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"f2\": f2,\n",
    "        \"mcc\": mcc,\n",
    "        \"mcc_normalized\": mcc_normalized,\n",
    "        \"S\": S,\n",
    "    }\n",
    "\n",
    "    # Report F2-score to Optuna and prune trial if applicable\n",
    "    if trial and trainer:\n",
    "        trial.report(f2, step=int(trainer.state.epoch))\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "id": "y_da1DP9beRq"
   },
   "id": "y_da1DP9beRq",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def suggest_hyperparameters(trial):\n",
    "    \"\"\"\n",
    "    Suggests hyperparameters for the model training using Optuna.\n",
    "\n",
    "    :param trial: Optuna trial object used for suggesting hyperparameters.\n",
    "    :return: Dictionary containing suggested hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_epochs = trial.suggest_int(\"num_train_epochs\", 2, 4)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
    "\n",
    "    # Compute total training steps dynamically\n",
    "    num_train_samples = len(train_dataset)\n",
    "    total_steps = (num_train_samples // batch_size) * num_epochs\n",
    "\n",
    "    # Compute warmup steps as 5-10% of total_steps\n",
    "    warmup_steps = int(trial.suggest_float(\"warmup_ratio\", 0.05, 0.1) * total_steps)\n",
    "\n",
    "    return {\n",
    "        \"num_train_epochs\": num_epochs,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 1e-4, log=True),\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.1),\n",
    "        \"warmup_steps\": warmup_steps\n",
    "    }\n",
    "\n",
    "def create_training_arguments(params, trial_number):\n",
    "    \"\"\"\n",
    "    Creates training arguments for the Trainer class.\n",
    "\n",
    "    :param params: Dictionary of hyperparameters for training.\n",
    "    :param trial_number: Trial number for tracking runs.\n",
    "    :return: TrainingArguments object with specified settings.\n",
    "    \"\"\"\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=params[\"num_train_epochs\"],\n",
    "        per_device_train_batch_size=params[\"batch_size\"],\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=params[\"warmup_steps\"],\n",
    "        weight_decay=params[\"weight_decay\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        report_to='wandb',\n",
    "        fp16=True,  # Mixed precision\n",
    "        run_name=f'Trial_{trial_number}_lr_{params[\"learning_rate\"]:.1e}_bs_{params[\"batch_size\"]}'\n",
    "    )"
   ],
   "metadata": {
    "id": "ru50wUPlwP8r"
   },
   "id": "ru50wUPlwP8r",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the objective function for training, optimization and logging\n",
    "\n",
    "Initalizes wandb run for each trial. Starts the model training and logs the metrics to the initialized wandb run. Plots confusion matrix. Returns S-Score and also tracks the best score."
   ],
   "metadata": {
    "id": "uE4pq16QHJWY"
   },
   "id": "uE4pq16QHJWY"
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize variables for tracking the best score and model\n",
    "best_score = None\n",
    "best_model_state_dict = None\n",
    "\n",
    "# Create an empty list to store the results\n",
    "all_results = []\n",
    "\n",
    "# Function return F2 score -> thats the value that study wants to maximize\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Defines the objective function for Optuna hyperparameter tuning.\n",
    "\n",
    "    :param trial: Optuna trial object.\n",
    "    :return: S score for model evaluation and hyperparameter optimization.\n",
    "    \"\"\"\n",
    "    global best_score, best_model_state_dict\n",
    "\n",
    "    # Create distinctive name for wandb run\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_name = f\"BERT_Extra_Layer_Trial_{trial.number}_{timestamp}\"\n",
    "\n",
    "    # Initialize WandB with a unique run ID\n",
    "    run = wandb.init(\n",
    "        project=\"German_Hate_Speech_Classification\",\n",
    "        name=run_name,\n",
    "        reinit=True,  # Force new run\n",
    "        id=run_name,  # Use trial number as unique ID\n",
    "    )\n",
    "\n",
    "    pruned_status = 0\n",
    "\n",
    "    try:\n",
    "        # Suggest hyperparameters\n",
    "        params = suggest_hyperparameters(trial)\n",
    "        training_args = create_training_arguments(params, trial.number)\n",
    "\n",
    "        logger.info(f\"num_train_epochs: {training_args.num_train_epochs}\")\n",
    "        logger.info(f\"per_device_train_batch_size: {training_args.per_device_train_batch_size}\")\n",
    "        logger.info(f\"per_device_eval_batch_size: {training_args.per_device_eval_batch_size}\")\n",
    "        logger.info(f\"warmup_steps: {training_args.warmup_steps}\")\n",
    "        logger.info(f\"weight_decay: {training_args.weight_decay}\")\n",
    "        logger.info(f\"learning_rate: {training_args.learning_rate}\")\n",
    "\n",
    "        wandb.config.update(training_args)\n",
    "\n",
    "        # Initialize model\n",
    "        model = BERT_WithExtraLayer(bert_model_name=\"deepset/gbert-base\", num_labels=2, class_weights=class_weights)\n",
    "        model.to(device)\n",
    "\n",
    "        # Trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=lambda eval_pred: compute_metrics(eval_pred, trial, trainer),\n",
    "        )\n",
    "\n",
    "        # Train and Evaluate\n",
    "        trainer.train()\n",
    "\n",
    "        # Get predictions on val_dataset\n",
    "        predictions = trainer.predict(val_dataset)\n",
    "\n",
    "        # Calculate metrics using compute_metrics function\n",
    "        eval_metrics = compute_metrics((predictions.predictions, predictions.label_ids))\n",
    "        logger.info(f\"Trial {trial.number} - Validation Metrics: {eval_metrics}\")\n",
    "\n",
    "        # Log metrics\n",
    "        wandb.log(eval_metrics)\n",
    "\n",
    "        # Get predictions on test_dataset\n",
    "        test_predictions = trainer.predict(test_dataset)\n",
    "        test_metrics = compute_metrics((test_predictions.predictions, test_predictions.label_ids))\n",
    "        logger.info(f\"Trial {trial.number} - Test Metrics: {test_metrics}\")\n",
    "\n",
    "        wandb.log(test_metrics)\n",
    "\n",
    "        logits, labels = test_predictions.predictions, test_predictions.label_ids\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Hate-Speech\", \"Hate-Speech\"])\n",
    "\n",
    "        # Plot the Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = disp.plot(cmap=plt.cm.Blues).ax_  # Get the Axes object of the plot\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=90, va='center')\n",
    "        plt.title(f\"Confusion Matrix for Trial {trial.number}\")\n",
    "\n",
    "        plt.tight_layout()  # Adjust layout for better spacing\n",
    "        plt.show()\n",
    "\n",
    "        all_results.append({\n",
    "            \"Trial_Name\": run_name,\n",
    "            \"Dataset\": dataset_filename,\n",
    "            \"Pruned\": pruned_status,\n",
    "            **eval_metrics,\n",
    "            **{f\"test_{k}\": v for k, v in test_metrics.items()}\n",
    "        })\n",
    "\n",
    "        current_score = eval_metrics[\"S\"]\n",
    "\n",
    "        # Compare and update the best model\n",
    "        if best_score is None or current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_model_state_dict = model.state_dict()  # Save the model's state dict\n",
    "            logger.info(f\"New best S score: {best_score}\")\n",
    "\n",
    "        return current_score  # Return Score for Optuna\n",
    "\n",
    "    except optuna.TrialPruned:\n",
    "        logger.info(f\"Trial {trial.number} pruned at epoch {trainer.state.epoch}\")\n",
    "        pruned_status = 1\n",
    "        all_results.append({\n",
    "            \"Trial_Name\": run_name,\n",
    "            \"Dataset\": dataset_filename,\n",
    "            \"Pruned\": pruned_status,  # Log pruned status\n",
    "        })\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # Ensure WandB run is closed properly\n",
    "        wandb.finish()"
   ],
   "metadata": {
    "id": "NUuD_jOzC1Wm"
   },
   "id": "NUuD_jOzC1Wm",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensure that wandb is terminating and session ends after training"
   ],
   "metadata": {
    "id": "w9cNPiP2HXiG"
   },
   "id": "w9cNPiP2HXiG"
  },
  {
   "cell_type": "code",
   "source": [
    "def safe_wandb_finish(timeout=45):\n",
    "    \"\"\"\n",
    "    Ensures safe termination of the WandB session with a timeout.\n",
    "\n",
    "    :param timeout: Maximum time (in seconds) to wait for WandB termination.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Safely terminates wandb.finish() with a timeout.\n",
    "    def finish_task():\n",
    "        try:\n",
    "            #import wandb\n",
    "            wandb.finish()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in wandb.finish(): {e}\")\n",
    "\n",
    "    finish_thread = threading.Thread(target=finish_task)\n",
    "    finish_thread.start()\n",
    "    finish_thread.join(timeout=timeout)  # Wait for up to `timeout` seconds\n",
    "\n",
    "    if finish_thread.is_alive():\n",
    "        logger.warning(\"wandb.finish() timed out. Proceeding with runtime.unassign().\")\n",
    "    else:\n",
    "        logger.info(\"wandb.finish() completed successfully.\")"
   ],
   "metadata": {
    "id": "yzWtKExm_Ajp"
   },
   "id": "yzWtKExm_Ajp",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main code for execution\n",
    "This code is used for objective execution, Bayes´ optimization, selecting and saving the best model as wells as logging the data. The HyperbandfPruner stops unpromising trials early."
   ],
   "metadata": {
    "id": "OC_LDlRhHxR_"
   },
   "id": "OC_LDlRhHxR_"
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "  try:\n",
    "      # Optuna Study. Uses MedianPruner as 'Early Stopping Method'\n",
    "      study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner(n_startup_trials=15, n_warmup_steps=3))\n",
    "\n",
    "      logger.info(f\"Sampler is {study.sampler.__class__.__name__}\") # TPESampler is default in Optuna. uses by default 10 Trials for its startup\n",
    "\n",
    "      study.optimize(objective, n_trials=50) # should be set to at least 10\n",
    "\n",
    "      # Additional logging in Excel file\n",
    "      excel_file_path = \"/content/drive/MyDrive/model/logged_model_metrics.xlsx\" # Check if the Excel file exists\n",
    "      if os.path.exists(excel_file_path):\n",
    "          # File exists, load and append new data\n",
    "          existing_df = pd.read_excel(excel_file_path, index_col=\"Trial_Name\")\n",
    "          new_df = pd.DataFrame(all_results)\n",
    "          new_df.set_index(\"Trial_Name\", inplace=True)\n",
    "          results_df = pd.concat([existing_df, new_df])  # Concatenate DataFrames\n",
    "      else:\n",
    "          # File doesn't exist, create new one\n",
    "          results_df = pd.DataFrame(all_results)\n",
    "          results_df.set_index(\"Trial_Name\", inplace=True)\n",
    "\n",
    "      # Save the DataFrame to the Excel file\n",
    "      results_df.to_excel(excel_file_path)\n",
    "\n",
    "      logger.info(f\"Trial results saved to: {excel_file_path}\")\n",
    "\n",
    "      # Log the best hyperparameters\n",
    "      best_params = study.best_params\n",
    "      logger.info(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "      timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "      # Save the best model and tokenizer\n",
    "      if best_model_state_dict is not None:\n",
    "          best_model_dir = f\"/content/drive/MyDrive/model/best_model_extra_Layer_{timestamp}\"\n",
    "          os.makedirs(best_model_dir, exist_ok=True)\n",
    "          best_trial = study.best_trial\n",
    "          logger.info(f\"Best Trial Number: {best_trial.number}\")\n",
    "\n",
    "          # create distinct model file name\n",
    "          model_filename = f\"model_extra_Layer_trial_{best_trial.number}_{timestamp}.bin\"\n",
    "\n",
    "          # model_filename = f\"pytorch_model_trial_{best_trial.number}_{timestamp}.pth\" # alternative file format\n",
    "\n",
    "          # Save model\n",
    "          torch.save(best_model_state_dict, os.path.join(best_model_dir, model_filename)) # this passes the mode.state_dict of the best model\n",
    "\n",
    "          # Save tokenizer\n",
    "          tokenizer.save_pretrained(best_model_dir)\n",
    "\n",
    "          logger.info(f\"Best model from Trial Number {best_trial.number} saved to {best_model_dir}\")\n",
    "\n",
    "          # wandb.finish()\n",
    "          safe_wandb_finish(timeout=45) # function needs to be revised again\n",
    "\n",
    "          logger.info(\"Process finished and terminated\")\n",
    "\n",
    "          # Allow threads to finish\n",
    "          time.sleep(5)\n",
    "\n",
    "          runtime.unassign()\n",
    "\n",
    "      else:\n",
    "          logger.error(\"No best model was found. Model could not be saved. Runtime will be terminated...\")\n",
    "          runtime.unassign()\n",
    "\n",
    "  except Exception as e:\n",
    "        # Logging and runtime termination\n",
    "        logger.error(f\"An error occurred during execution: {str(e)}\", exc_info=True)\n",
    "        runtime.unassign()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "37f9299916e04d22ae5235f5cb06e7ae",
      "4ba7605759f34ba9918e95225919ba95",
      "78a1b2dba87f4e11b3159256f1368c09",
      "3c6d151ea1dd4a17bf193be817e8e531",
      "fc722d7518e54173baac0347886e352b",
      "a100851a2a8c40e5aef798d888b71ae7",
      "2692a0cf9e1e4e7dbf6f5c0550c12426",
      "768e618685e3482498b5ab2c049e6efc",
      "06e3420e9ca643f0b79478803c3087de",
      "39c154e5d111457fa7af3eb72057264e",
      "8a569007d29443758b20ad6050cbc6ae"
     ],
     "output_embedded_package_id": "1CzJ0HSqBssoRmX1Ipokyspwyk3nQAwjG"
    },
    "id": "CGn14-F6i7v5",
    "outputId": "1b394121-80ed-4fa5-978d-3b8b232e9f32"
   },
   "id": "CGn14-F6i7v5",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output hidden; open in https://colab.research.google.com to view."
     },
     "metadata": {}
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "L4",
   "machine_shape": "hm"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
        "b2c9e8b033f1451e89d2efb8f72caec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_774c1612763c4b71a831a9fff5af4b9b",
       "IPY_MODEL_af99f15763a14caaa099176dd4834950",
       "IPY_MODEL_f84a8cc972e747269372bff1058391a9"
      ],
      "layout": "IPY_MODEL_1bf21ae404ce4eb5861e0d90c1a5c90b"
     }
    },
    "774c1612763c4b71a831a9fff5af4b9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb21b8d54b6748ddaea92b59f65ded40",
      "placeholder": "​",
      "style": "IPY_MODEL_da386aeb94a74293bb41f3055d784924",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "af99f15763a14caaa099176dd4834950": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82620d7f165c4dea9bfda4c1552a8ef3",
      "max": 83,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23e8053878a54447bebb3ef351a90eff",
      "value": 83
     }
    },
    "f84a8cc972e747269372bff1058391a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b7b369c167141c0aef96d926c885ad8",
      "placeholder": "​",
      "style": "IPY_MODEL_36b9a5f2e38c4413ae9763961106e2a4",
      "value": " 83.0/83.0 [00:00&lt;00:00, 7.20kB/s]"
     }
    },
    "1bf21ae404ce4eb5861e0d90c1a5c90b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb21b8d54b6748ddaea92b59f65ded40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da386aeb94a74293bb41f3055d784924": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82620d7f165c4dea9bfda4c1552a8ef3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23e8053878a54447bebb3ef351a90eff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9b7b369c167141c0aef96d926c885ad8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36b9a5f2e38c4413ae9763961106e2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac0be628989645e986f4944a8b0acb52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d136d7a74154b94833d1ac1edf4d3b4",
       "IPY_MODEL_14071f4d05a64ac1be14620a56e17f04",
       "IPY_MODEL_0ef914e20a7841cbbe852b2fd492be5c"
      ],
      "layout": "IPY_MODEL_e7aebb90a6074a60a472f2aaba925d78"
     }
    },
    "8d136d7a74154b94833d1ac1edf4d3b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f09de98447f34fb690b06b8138c2b499",
      "placeholder": "​",
      "style": "IPY_MODEL_b96367c3c55b475fbe0c01bb507d8f63",
      "value": "config.json: 100%"
     }
    },
    "14071f4d05a64ac1be14620a56e17f04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b806cf0d9b604b0197aa66519e6e2eff",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed839d82b0d54aba84b469fb625f2504",
      "value": 362
     }
    },
    "0ef914e20a7841cbbe852b2fd492be5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a0a452bb92e4bdb8892dfdae6dc0dd0",
      "placeholder": "​",
      "style": "IPY_MODEL_81a1c27ab3cf433396ba6e3578ab6e2f",
      "value": " 362/362 [00:00&lt;00:00, 30.5kB/s]"
     }
    },
    "e7aebb90a6074a60a472f2aaba925d78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f09de98447f34fb690b06b8138c2b499": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b96367c3c55b475fbe0c01bb507d8f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b806cf0d9b604b0197aa66519e6e2eff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed839d82b0d54aba84b469fb625f2504": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a0a452bb92e4bdb8892dfdae6dc0dd0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81a1c27ab3cf433396ba6e3578ab6e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "01b6eff419654533bb487875ba6f95a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e5e450f26bf4eccba5e4d0ca76504bc",
       "IPY_MODEL_03fe074b30e34202b65379a70eeef9bb",
       "IPY_MODEL_ced62a16e9b44ee59f285205a06c6d04"
      ],
      "layout": "IPY_MODEL_be6c5d1ba184453fb14dcf2edfbd6d97"
     }
    },
    "2e5e450f26bf4eccba5e4d0ca76504bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b111594fae8b400585cd661c17189f56",
      "placeholder": "​",
      "style": "IPY_MODEL_b2690f0494fc4525a4bfc1505cdec409",
      "value": "vocab.txt: 100%"
     }
    },
    "03fe074b30e34202b65379a70eeef9bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fc65ce5a0c34ab1a6aafcedace9237e",
      "max": 239836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f590cd58c9cc428c967d954153498e2b",
      "value": 239836
     }
    },
    "ced62a16e9b44ee59f285205a06c6d04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94b6d3326d044c3fa50c2104f7dac56e",
      "placeholder": "​",
      "style": "IPY_MODEL_67563fe012ab4ac382a4d7159ddec5f0",
      "value": " 240k/240k [00:00&lt;00:00, 3.10MB/s]"
     }
    },
    "be6c5d1ba184453fb14dcf2edfbd6d97": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b111594fae8b400585cd661c17189f56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2690f0494fc4525a4bfc1505cdec409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fc65ce5a0c34ab1a6aafcedace9237e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f590cd58c9cc428c967d954153498e2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94b6d3326d044c3fa50c2104f7dac56e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67563fe012ab4ac382a4d7159ddec5f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37f9299916e04d22ae5235f5cb06e7ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ba7605759f34ba9918e95225919ba95",
       "IPY_MODEL_78a1b2dba87f4e11b3159256f1368c09",
       "IPY_MODEL_3c6d151ea1dd4a17bf193be817e8e531"
      ],
      "layout": "IPY_MODEL_fc722d7518e54173baac0347886e352b"
     }
    },
    "4ba7605759f34ba9918e95225919ba95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a100851a2a8c40e5aef798d888b71ae7",
      "placeholder": "​",
      "style": "IPY_MODEL_2692a0cf9e1e4e7dbf6f5c0550c12426",
      "value": "model.safetensors: 100%"
     }
    },
    "78a1b2dba87f4e11b3159256f1368c09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_768e618685e3482498b5ab2c049e6efc",
      "max": 442233876,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06e3420e9ca643f0b79478803c3087de",
      "value": 442233876
     }
    },
    "3c6d151ea1dd4a17bf193be817e8e531": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39c154e5d111457fa7af3eb72057264e",
      "placeholder": "​",
      "style": "IPY_MODEL_8a569007d29443758b20ad6050cbc6ae",
      "value": " 442M/442M [00:01&lt;00:00, 225MB/s]"
     }
    },
    "fc722d7518e54173baac0347886e352b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a100851a2a8c40e5aef798d888b71ae7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2692a0cf9e1e4e7dbf6f5c0550c12426": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "768e618685e3482498b5ab2c049e6efc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06e3420e9ca643f0b79478803c3087de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39c154e5d111457fa7af3eb72057264e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a569007d29443758b20ad6050cbc6ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
    }
    
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
